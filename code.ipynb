{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5a3c0e8",
   "metadata": {},
   "source": [
    "# Kaggle MNIST Challenge: Digit Recognizer\n",
    "### By Aninda Metta Citta and Liao Ru Xin, Juliette\n",
    "\n",
    "This notebook walks through our solution for the Digit Recognizer challenge. The goal is to build our own neural network that can take an image of a handwritten single digit from 28x28 pixel images, and determine what that digit is using the Kaggle MNIST dataset. Our workflow includes loading the data, preprocessing, model training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "521b7e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18db596e",
   "metadata": {},
   "source": [
    "## Dataset and Preprocessing\n",
    "\n",
    "The Kaggle dataset is provided as a CSV file. Each row is one handwritten digit image:\n",
    "- **First column**: the actual digit (0-9)\n",
    "- **Next 784 columns**: pixel intensities from the 28Ã—28 image, flattened into a single row\n",
    "\n",
    "A custom PyTorch `Dataset` class is implemented to:\n",
    "1. Load CSV file\n",
    "2. Separate labels from pixels\n",
    "3. Reshape the flattened array into 28x28 images\n",
    "4. Normalise pixel intensities (between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe6bc7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTTrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_filename, transform=None, target_transform=None):\n",
    "        self.data = pd.read_csv(csv_filename, skiprows=0) # skip the header\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.data.iloc[idx, 0]\n",
    "        image = np.array(list(self.data.iloc[idx,1:]), dtype=np.float32) # all columns but the first\n",
    "        image = image / image.max() # to set image dynamic range to [0, 1]\n",
    "        image = image.reshape((28, 28)) # dimension conversion (784) to (28,28)\n",
    "        if self.transform: # apply an transforms given as input\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return image, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f62361",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTTestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_filename, transform=None, target_transform=None):\n",
    "        self.data = pd.read_csv(csv_filename, skiprows=0) # skip the header\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array(list(self.data.iloc[idx,0:]), dtype=np.float32) # all columns since there is no label\n",
    "        image = image / image.max() # to set image dynamic range to [0, 1]\n",
    "        image = image.reshape((28, 28)) # dimension conversion (784) to (28,28)\n",
    "        if self.transform: # apply an transforms given as input\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12c14f9",
   "metadata": {},
   "source": [
    "## Train and Test sets\n",
    "\n",
    "The Kaggle Challenge provides two dataset: train.csv which is labelled and test.csv which is not labelled. From the previous section, we have created MNISTTrainDataset and MNISTTestDataset to read the two different csv respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eec2a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNISTTrainDataset(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "25b3a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MNISTTestDataset(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3751f3f4",
   "metadata": {},
   "source": [
    "## DataLoader Setup\n",
    "\n",
    "DataLoaders are used to:\n",
    "- batch samples (batch size = 64 which balances training speed and memory use)\n",
    "- shuffle the training data each epoch (helps model with learning instead of just memorising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec318527",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6050815b",
   "metadata": {},
   "source": [
    "## Model: Baseline Fully Connected Neural Network\n",
    "\n",
    "A simple baseline network is used:\n",
    "- `fc1`: Input layer takes in all 784 pixels (28x28 flattened)\n",
    "- 128 neurons with ReLU activation which introduces non-linearity\n",
    "- `fc2`: Output layer maps 128 to 10 neurons (one for each digit)\n",
    "\n",
    "In the forward pass:\n",
    "- input image tensor is flattened from `(batch, 1, 28, 28)` into `(batch, 784)` using `view`\n",
    "- run through hidden layer with ReLU\n",
    "- final output is raw scores for each digit class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "caeb0e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716cd295",
   "metadata": {},
   "source": [
    "## Loss Function and Optimisation\n",
    "\n",
    "- **Loss function:** `CrossEntropyLoss` is used for multi-class classification. It expects raw logits from the model and labels as integers\n",
    "- **Optimiser:** `Adam` with learning rate 0.001 is used due to its stable performance and adaptive learning rate behavior.\n",
    "- **Epochs:** 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a801d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DigitNet()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee2c289",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "This is where learning occurs. For each epoch:\n",
    "1. Set the model to training mode with `model.train()`\n",
    "2. Iterate over batches from `train_loader`\n",
    "3. Compute outputs (forward pass) and loss\n",
    "4. Zero gradients, backpropagate (`loss.backward()`), and update parameters to improve predictions (`optimiser.step()`)\n",
    "5. Track and print the average loss per epoch\n",
    "\n",
    "We printed the training loss for each epoch to helps verify that the model is learning (loss should generally decrease over epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06991f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.3882\n",
      "Epoch [2/5], Loss: 0.1735\n",
      "Epoch [3/5], Loss: 0.1220\n",
      "Epoch [4/5], Loss: 0.0934\n",
      "Epoch [5/5], Loss: 0.0741\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward pass\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50495fed",
   "metadata": {},
   "source": [
    "## Validation DataLoader\n",
    "\n",
    "A separate DataLoader is created for the validation set. Shuffling is not needed as we want to evaluate performance consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24e8652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876c430d",
   "metadata": {},
   "source": [
    "## Model Prediction\n",
    "\n",
    "This is where we see how well our model works on data is hasn't seen during training.\n",
    "- Switch the model to evaluation mode with `model.eval()`\n",
    "- Disable gradient computation with `torch.no_grad()` (saves memory and time)\n",
    "- Compute predicted class labels using `torch.max(outputs, 1)`\n",
    "\n",
    "Finally, we saved the predicted class labels into the CSV file \"mnist_test_predictions.csv\" for submission to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc9dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.append(predicted)\n",
    "\n",
    "# Concatenate all batches\n",
    "all_preds = torch.cat(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fc9765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to CSV\n",
    "final_prediction = pd.DataFrame(all_preds.numpy(), columns=[\"Label\"]).reset_index()\n",
    "final_prediction['index'] = final_prediction.index + 1\n",
    "final_prediction = final_prediction.rename(columns={'predicted': 'Label', 'index': 'ImageId'})\n",
    "final_prediction.to_csv(\"mnist_test_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd18cea",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates an end-to-end baseline pipeline for Kaggle MNIST digit recogniser:\n",
    "- A custom Dataset is used to load CSV rows as images and labels\n",
    "- The dataset is split into training and validation sets\n",
    "- A simple fully connected neural network is trained using CrossEntropyLoss and Adam\n",
    "- Validation accuracy is computed to assess performance on unseen data.\n",
    "\n",
    "#### Possible Improvements\n",
    "\n",
    "- Use convolutional neural networks (CNNs) which would probably improve accuracy\n",
    "- More training with greater number of epochs\n",
    "- Experiment with learning rate, batch size etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
