{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5a3c0e8",
   "metadata": {},
   "source": [
    "# Kaggle MNIST Challenge: Digit Recognizer\n",
    "### By Aninda Metta Citta and Liao Ru Xin, Juliette\n",
    "\n",
    "This notebook walks through our solution for the Digit Recognizer challenge. The goal is to build our own neural network that can take an image of a handwritten single digit from 28x28 pixel images, and determine what that digit is using the Kaggle MNIST dataset. Our workflow includes loading the data, preprocessing, model training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "521b7e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18db596e",
   "metadata": {},
   "source": [
    "## Dataset and Preprocessing\n",
    "\n",
    "The Kaggle dataset is provided as a CSV file. Each row is one handwritten digit image:\n",
    "- **First column**: the actual digit (0-9)\n",
    "- **Next 784 columns**: pixel intensities from the 28Ã—28 image, flattened into a single row\n",
    "\n",
    "A custom PyTorch `Dataset` class is implemented to:\n",
    "1. Load CSV file\n",
    "2. Separate labels from pixels\n",
    "3. Reshape the flattened array into 28x28 images\n",
    "4. Normalize pixel intensities (between 0 and 1)\n",
    "5. Convert data into PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fe6bc7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTTrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_filename, transform=None, target_transform=None):\n",
    "        self.data = pd.read_csv(csv_filename, skiprows=0) # skip the header\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.data.iloc[idx, 0]\n",
    "        image = np.array(list(self.data.iloc[idx,1:]), dtype=np.float32) # all columns but the first\n",
    "        image = image / image.max() # to set image dynamic range to [0, 1]\n",
    "        image = image.reshape((28, 28)) # dimension conversion (784) to (28,28)\n",
    "        if self.transform: # apply an transforms given as input\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return image, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12c14f9",
   "metadata": {},
   "source": [
    "## Train and Test sets\n",
    "\n",
    "The dataset is split into training (80%) and validation (20%) sets. We made use of PyTorch's `random_split` which randomly divides the dataset into non-overlapping subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ad1b4126",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = MNISTTrainDataset(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1e6c4203",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    full_dataset,\n",
    "    [train_size, test_size]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3751f3f4",
   "metadata": {},
   "source": [
    "## DataLoader Setup\n",
    "\n",
    "DataLoaders are used to:\n",
    "- batch samples (batch size = 64 which balances training speed and memory use)\n",
    "- shuffle the training data each epoch (helps model with learning instead of just memorising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ec318527",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6050815b",
   "metadata": {},
   "source": [
    "## Model: Baseline Fully Connected Neural Network\n",
    "\n",
    "A simple baseline network is used:\n",
    "- `fc1`: Input layer takes in all 784 pixels (28x28 flattened)\n",
    "- 128 neurons with ReLU activation which introduces non-linearity\n",
    "- `fc2`: Output layer maps 128 to 10 neurons (one for each digit)\n",
    "\n",
    "In the forward pass:\n",
    "- input image tensor is flattened from `(batch, 1, 28, 28)` into `(batch, 784)` using `view`\n",
    "- run through hidden layer with ReLU\n",
    "- final output is raw scores for each digit class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "caeb0e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716cd295",
   "metadata": {},
   "source": [
    "## Loss Function and Optimisation\n",
    "\n",
    "- **Loss function:** `CrossEntropyLoss` is used for multi-class classification. It expects raw logits from the model and labels as integers\n",
    "- **Optimiser:** `Adam` with learning rate 0.001 is used due to its stable performance and adaptive learning rate behavior.\n",
    "- **Epochs:** 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8a801d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DigitNet()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee2c289",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "This is where learning occurs. For each epoch:\n",
    "1. Set the model to training mode with `model.train()`\n",
    "2. Iterate over batches from `train_loader`\n",
    "3. Compute outputs (forward pass) and loss\n",
    "4. Zero gradients, backpropagate (`loss.backward()`), and update parameters to improve predictions (`optimiser.step()`)\n",
    "5. Track and print the average loss per epoch\n",
    "\n",
    "We printed the training loss for each epoch to helps verify that the model is learning (loss should generally decrease over epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "06991f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.4358\n",
      "Epoch [2/5], Loss: 0.2172\n",
      "Epoch [3/5], Loss: 0.1618\n",
      "Epoch [4/5], Loss: 0.1268\n",
      "Epoch [5/5], Loss: 0.1017\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward pass\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50495fed",
   "metadata": {},
   "source": [
    "## Validation DataLoader\n",
    "\n",
    "A separate DataLoader is created for the validation set. Shuffling is not needed as we want to evaluate performance consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "24e8652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876c430d",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "This is where we see how well our model works on data is hasn't seen during training.\n",
    "- Switch the model to evaluation mode with `model.eval()`\n",
    "- Disable gradient computation with `torch.no_grad()` (saves memory and time)\n",
    "- Compute predicted class labels using `torch.max(outputs, 1)`\n",
    "- Compare predictions to true labels to compute accuracy\n",
    "\n",
    "Accuracy shows the percentage of digits correctly identified by the model in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3cc9dd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 96.00%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd18cea",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates an end-to-end baseline pipeline for Kaggle MNIST digit recogniser:\n",
    "- A custom Dataset is used to load CSV rows as images and labels\n",
    "- The dataset is split into training and validation sets\n",
    "- A simple fully connected neural network is trained using CrossEntropyLoss and Adam\n",
    "- Validation accuracy is computed to assess performance on unseen data.\n",
    "\n",
    "#### Possible Improvements\n",
    "\n",
    "- Use convolutional neural networks (CNNs) which would probably improve accuracy\n",
    "- More training with greater number of epochs\n",
    "- Experiment with learning rate, batch size etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
